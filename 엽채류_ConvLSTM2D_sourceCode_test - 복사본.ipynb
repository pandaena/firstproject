{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773cde0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 모듈\n",
    "from re import X\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import io\n",
    "import imageio\n",
    "import cv2\n",
    "from glob import glob\n",
    "from PIL import Image as img\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "import pandas as pd\n",
    "import codecs, json\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b4f5f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 사용 이미지\n",
    "# import glob\n",
    "# IMG_PATH = Path('D:/data/1.Training_crop_merge')\n",
    "#   # 근대만 모은 폴더\n",
    "\n",
    "# # 생장 데이터\n",
    "# DATASET_PATH = Path('D:/data/1.Training/labels_merge')\n",
    "\n",
    "# # 환경 데이터\n",
    "# DATACSV_PATH = Path('D:/data/1.Training/labels_merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ebb36933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 이미지\n",
    "import glob\n",
    "\n",
    "# grop으로 이미지 불러오기\n",
    "img_file = r'E:/data/1.Training_crop_merge/*.jpg'\n",
    "IMG = glob.glob(img_file)\n",
    "\n",
    "\n",
    "# 생장 데이터\n",
    "wdata_file = r'E:/data/1.Training/labels_merge/*.json'\n",
    "DATASET = glob.glob(wdata_file)\n",
    "\n",
    "# 환경 데이터\n",
    "sdata_file = r'E:/data/1.Training/labels_merge/*json'\n",
    "DATACSV = glob.glob(sdata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "866f005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"img_file.txt\", \"w\") as f:\n",
    "    for ls in IMG:\n",
    "        f.write(ls)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"wdata_file.txt\", \"w\") as f:\n",
    "    for ls in DATASET:\n",
    "        f.write(ls)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with open(\"sdata_file.txt\", \"w\") as f:\n",
    "    for ls in DATACSV:\n",
    "        f.write(ls)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a92a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH ='E:/data/img_file.txt'\n",
    "DATASET_PATH = 'E:/data/wdata_file.txt'\n",
    "DATACSV_PATH = 'E:/data/sdata_file.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc5e6640",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_trainset = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c12ba3af",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# dataset 저장할 때 사용하는 함수\n",
    "\n",
    "def write_dataset(fname, wdataset, idataset, sdataset ) :\n",
    "  ## fname 은 저장할 txt파일 save_cashe + '/train_data.txt'\n",
    "  ## nia 는 한국지능정보사회진흥원에 보낼 데이터들\n",
    "\n",
    "    with open(fname, \"w\") as wfile:\n",
    "        for idx,value in enumerate(idataset) :\n",
    "            niadata = { \"leaf_length\" : wdataset[idx], \"image\" : value, \"env\" : sdataset[idx] }\n",
    "            # For test\n",
    "            # for idximg in value:\n",
    "            #     print(f'images : { str(IMG_PATH) + \"/\" + idximg.split(\"/\")[-1]}')\n",
    "            #     img = cv2.imread( str(IMG_PATH) +'/' + idximg.split('/')[-1] )\n",
    "            #     cv2.imwrite('./wdataset/temp/'+ str(wdataset[idx]) + '_' + idximg.split('/')[-1],cv2.resize(img,(400,400)))\n",
    "            # sdataset에는 기존 코드에 있던 생장정보가 아닌 환경 정보 넣기\n",
    "            # wdataset은 무게가 아닌 잎 길이 정보 넣기\n",
    "            wfile.write(str(niadata) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a5d69a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잎 찾기 함수\n",
    "# 소스코드에서 사용된 적 없음\n",
    "\n",
    "def detect_leaf(imgfile):\n",
    "\n",
    "    img = cv2.imread(imgfile)\n",
    "\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # find the green color \n",
    "    # mask_green = cv2.inRange(hsv, (36,0,0), (86,255,255))\n",
    "\n",
    "    # find the brown color\n",
    "    mask_brown = cv2.inRange(hsv, (8, 60, 20), (30, 255, 200))\n",
    "    # find the yellow and green color in the leaf\n",
    "    mask_yellow_green = cv2.inRange(hsv, low_green, high_green)\n",
    "    # find any of the three colors(green or brown or yellow) in the image\n",
    "\n",
    "    mask = cv2.bitwise_or(mask_yellow_green, mask_brown)\n",
    "    \n",
    "    # mask = cv2.bitwise_or(mask, mask_yellow_green)\n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "    cv2.imshow(\"original\", img)\n",
    "    cv2.imshow(\"final image\", res)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8b2b602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 마스크\n",
    "# 마스크 함수 이용 안 하고 전처리 해놓은 이미지 사용할 예정\n",
    "# 다른 함수 속에 들어가서 실행되는 거라면 코드 수정해줘야함\n",
    "RESIZE=64\n",
    "def img_mask( imgfile, masked ) :\n",
    "#     이미지 불러게만 바꿔줌\n",
    "\n",
    "\n",
    "    imgorg = green = cv2.imread(imgfile)\n",
    "#     if masked :\n",
    "#         hsv = cv2.cvtColor(imgorg, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "#         # find the green color \n",
    "#         mask_green = cv2.inRange(hsv, (25,0,117), (171,194,192))\n",
    "#         # find the brown color\n",
    "#         mask_brown = cv2.inRange(hsv, (19, 60, 112), (179, 186, 222))\n",
    "#         # find the yellow color in the leaf\n",
    "#         mask_yellow = cv2.inRange(hsv, (36, 0, 0), (136, 255, 255))\n",
    "#         # hsv = cv2.morphologyEx(hsv, cv2.MORPH_CLOSE, kernel=np.ones((11,11),dtype=np.uint8))\n",
    "#         # apply mask to original image\n",
    "#         # green = cv2.bitwise_and(imgorg, imgorg,mask=mask)\n",
    "\n",
    "#         mask = cv2.bitwise_or(mask_green, mask_brown)\n",
    "#         mask = cv2.bitwise_or(mask, mask_yellow)\n",
    "\n",
    "#         result = cv2.bitwise_and(imgorg, imgorg, mask=mask)\n",
    "\n",
    "#         result = cv2.morphologyEx(result, cv2.MORPH_CLOSE, kernel=np.ones((11,11),dtype=np.uint8))\n",
    "\n",
    "#         cv2.imshow(\"original\", imgorg)\n",
    "#         cv2.imshow(\"middle image\", hsv)\n",
    "#         cv2.imshow(\"final image\", result)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "\n",
    "    return green\n",
    "\n",
    "def img_mask3( imgfile, masked ) :\n",
    "\n",
    "    low_green = np.array([155,0,40])\n",
    "    high_green = np.array([179,165,255])\n",
    "    low_red = np.array([42,127,81])\n",
    "    high_red= np.array([179,254,255])\n",
    "\n",
    "    imgorg = green = cv2.imread(imgfile)\n",
    "    if masked :\n",
    "        hsv = cv2.cvtColor(imgorg, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # hsv = cv2.morphologyEx(hsv, cv2.MORPH_CLOSE, kernel=np.ones((11,11),dtype=np.uint8))\n",
    "        # apply mask to original image\n",
    "        # green = cv2.bitwise_and(imgorg, imgorg,mask=mask)\n",
    "\n",
    "        mask = cv2.bitwise_not(cv2.inRange(hsv, low_green, high_green))\n",
    "        mask2 = cv2.bitwise_not(cv2.inRange(hsv, low_red, high_red))\n",
    "\n",
    "        mask =cv2.bitwise_not(mask+mask2)\n",
    "        ## slice the green\n",
    "\n",
    "        result = cv2.bitwise_and(imgorg, imgorg, mask=mask)\n",
    "        result = cv2.morphologyEx(result, cv2.MORPH_CLOSE, kernel=np.ones((11,11),dtype=np.uint8))\n",
    "\n",
    "        cv2.imshow(\"original\", imgorg)\n",
    "        cv2.imshow(\"middle image\", hsv)\n",
    "        cv2.imshow(\"final image\", result)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    return result\n",
    "\n",
    "def img_mask2( imgfile, masked ) :\n",
    "    imgorg = green = cv2.imread(imgfile)\n",
    "    if masked :\n",
    "\n",
    "        # imgorg = cv2.adaptiveThreshold(imgorg,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,15,2)\n",
    "\n",
    "        low_green = np.array([20,144,88])\n",
    "        high_green = np.array([167,247,164])\n",
    "\n",
    "        mask = cv2.inRange(imgorg, (86,66,0), (190,190,255))\n",
    "        cv2.imshow(\"1\", mask)\n",
    "\n",
    "        mask2 = cv2.bitwise_not(mask)\n",
    "        cv2.imshow(\"2\", mask2)\n",
    "\n",
    "        # output = cv2.bitwise_and(imgorg,imgorg, mask= mask)\n",
    "\n",
    "        hsv = cv2.cvtColor(imgorg, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # hsv = cv2.morphologyEx(hsv, cv2.MORPH_CLOSE, kernel=np.ones((11,11),dtype=np.uint8))\n",
    "        # apply mask to original image\n",
    "        # green = cv2.bitwise_and(imgorg, imgorg,mask=mask)\n",
    "\n",
    "        mask = cv2.inRange(hsv, low_green, high_green)\n",
    "        ## slice the green\n",
    "\n",
    "        result = cv2.bitwise_and(imgorg, imgorg, mask=mask)\n",
    "        result2 = cv2.bitwise_and(result, result, mask=mask2)\n",
    "\n",
    "        result = cv2.morphologyEx(result, cv2.MORPH_CLOSE, kernel=np.ones((11,11),dtype=np.uint8))\n",
    "        result2 = cv2.morphologyEx(result2, cv2.MORPH_CLOSE, kernel=np.ones((11,11),dtype=np.uint8))\n",
    "\n",
    "        cv2.imshow(\"original\", imgorg)\n",
    "        cv2.imshow(\"final image\", result2)\n",
    "        cv2.imshow(\"middle image\", result)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22de9edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소스코드에 사용된 적 없음\n",
    "\n",
    "def kmeans_color_quantization(image, clusters=8, rounds=1):\n",
    "    h, w = image.shape[:2]\n",
    "    samples = np.zeros([h*w,3], dtype=np.float32)\n",
    "    count = 0\n",
    "\n",
    "    for x in range(h):\n",
    "        for y in range(w):\n",
    "            samples[count] = image[x][y]\n",
    "            count += 1\n",
    "\n",
    "    compactness, labels, centers = cv2.kmeans(samples,\n",
    "            clusters, \n",
    "            None,\n",
    "            (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10000, 0.0001), \n",
    "            rounds, \n",
    "            cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    centers = np.uint8(centers)\n",
    "    res = centers[labels.flatten()]\n",
    "    return res.reshape((image.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4966dd14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                  filename_mod create_date crops kind_type  \\\n0    C26_L04_01_001_439336.jpg  2021-11-08    근대      청경근대   \n1    C26_L04_01_001_439874.jpg  2021-11-08    근대      청경근대   \n2    C26_L04_01_001_559451.jpg  2021-12-01    근대      청경근대   \n3    C26_L04_01_002_439009.jpg  2021-11-08    근대      청경근대   \n4    C26_L04_01_002_439331.jpg  2021-11-08    근대      청경근대   \n..                         ...         ...   ...       ...   \n242  C29_L04_02_009_551466.jpg  2021-11-25    근대      청경근대   \n243  C29_L04_02_009_552167.jpg  2021-11-25    근대      청경근대   \n244  C29_L04_02_009_553050.jpg  2021-11-25    근대      청경근대   \n245  C29_L04_02_009_553890.jpg  2021-11-25    근대      청경근대   \n246  C29_L04_02_009_580489.jpg  2021-12-03    근대      청경근대   \n\n                               fname growth_stage         receive_date  \\\n0    C26_L04_01_001_210914213908.jpg          생육기  2021-09-14 21:38:54   \n1    C26_L04_01_001_210923213908.jpg          생육기  2021-09-23 21:38:42   \n2    C26_L04_01_001_210927213908.jpg          수확기  2021-09-27 21:38:11   \n3    C26_L04_01_002_210907213908.jpg          생육기  2021-09-07 21:38:56   \n4    C26_L04_01_002_210914133908.jpg          생육기  2021-09-14 13:38:59   \n..                               ...          ...                  ...   \n242  C29_L04_01_009_211019171257.jpg          정식기  2021-10-19 17:12:24   \n243  C29_L04_01_009_211026170959.jpg          생육기  2021-10-26 17:09:17   \n244  C29_L04_01_009_211102160959.jpg          생육기  2021-11-02 16:09:47   \n245  C29_L04_01_009_211109160959.jpg          생육기  2021-11-09 16:09:38   \n246  C29_L04_01_009_211116140959.jpg          수확기  2021-11-16 14:09:06   \n\n    temp_min humi_min co2_min  ... ei_value pl_value measured_date  \\\n0       21.0     50.0   255.0  ...     0.14      4.5    2021-09-14   \n1       21.0     54.0   184.0  ...     0.16      4.7    2021-09-23   \n2       21.0     59.0   179.0  ...     0.17      4.7    2021-09-27   \n3       21.0     50.0   275.0  ...     0.12      4.5    2021-09-07   \n4       19.0     51.0   265.0  ...     0.14      4.8    2021-09-14   \n..       ...      ...     ...  ...      ...      ...           ...   \n242     19.0     48.0   394.0  ...     0.18      4.2    2021-10-19   \n243     21.0     48.0   428.0  ...     0.20      3.9    2021-10-26   \n244     21.0     47.0   385.0  ...     0.22      4.0    2021-11-02   \n245     21.0     48.0   336.0  ...     0.25      3.9    2021-11-09   \n246     22.0     49.0   329.0  ...     0.29      3.7    2021-11-16   \n\n    stem_length leaf_cnt leaf_width leaf_length stem_thick fr_weight  \\\n0          5.9        2        2.5         3.4           0         0   \n1         13.0        5        3.5         4.2           0         0   \n2         16.0        6        5.9         7.2           0      8.0    \n3          6.2        2        2.0         3.3           0         0   \n4         11.0        2        2.8         3.7           0         0   \n..          ...      ...        ...         ...        ...       ...   \n242         2.4        2        0.9         1.3          0         0   \n243         4.7        4        1.1         1.5          0         0   \n244         6.2        4        1.7         2.7          0         0   \n245           9        6          3         4.5          0         0   \n246       10.8         8       4.5         4.7           0         4   \n\n          cameranum  \n0    C26_L04_01_001  \n1    C26_L04_01_001  \n2    C26_L04_01_001  \n3    C26_L04_01_002  \n4    C26_L04_01_002  \n..              ...  \n242  C29_L04_02_009  \n243  C29_L04_02_009  \n244  C29_L04_02_009  \n245  C29_L04_02_009  \n246  C29_L04_02_009  \n\n[247 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename_mod</th>\n      <th>create_date</th>\n      <th>crops</th>\n      <th>kind_type</th>\n      <th>fname</th>\n      <th>growth_stage</th>\n      <th>receive_date</th>\n      <th>temp_min</th>\n      <th>humi_min</th>\n      <th>co2_min</th>\n      <th>...</th>\n      <th>ei_value</th>\n      <th>pl_value</th>\n      <th>measured_date</th>\n      <th>stem_length</th>\n      <th>leaf_cnt</th>\n      <th>leaf_width</th>\n      <th>leaf_length</th>\n      <th>stem_thick</th>\n      <th>fr_weight</th>\n      <th>cameranum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>C26_L04_01_001_439336.jpg</td>\n      <td>2021-11-08</td>\n      <td>근대</td>\n      <td>청경근대</td>\n      <td>C26_L04_01_001_210914213908.jpg</td>\n      <td>생육기</td>\n      <td>2021-09-14 21:38:54</td>\n      <td>21.0</td>\n      <td>50.0</td>\n      <td>255.0</td>\n      <td>...</td>\n      <td>0.14</td>\n      <td>4.5</td>\n      <td>2021-09-14</td>\n      <td>5.9</td>\n      <td>2</td>\n      <td>2.5</td>\n      <td>3.4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>C26_L04_01_001</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>C26_L04_01_001_439874.jpg</td>\n      <td>2021-11-08</td>\n      <td>근대</td>\n      <td>청경근대</td>\n      <td>C26_L04_01_001_210923213908.jpg</td>\n      <td>생육기</td>\n      <td>2021-09-23 21:38:42</td>\n      <td>21.0</td>\n      <td>54.0</td>\n      <td>184.0</td>\n      <td>...</td>\n      <td>0.16</td>\n      <td>4.7</td>\n      <td>2021-09-23</td>\n      <td>13.0</td>\n      <td>5</td>\n      <td>3.5</td>\n      <td>4.2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>C26_L04_01_001</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>C26_L04_01_001_559451.jpg</td>\n      <td>2021-12-01</td>\n      <td>근대</td>\n      <td>청경근대</td>\n      <td>C26_L04_01_001_210927213908.jpg</td>\n      <td>수확기</td>\n      <td>2021-09-27 21:38:11</td>\n      <td>21.0</td>\n      <td>59.0</td>\n      <td>179.0</td>\n      <td>...</td>\n      <td>0.17</td>\n      <td>4.7</td>\n      <td>2021-09-27</td>\n      <td>16.0</td>\n      <td>6</td>\n      <td>5.9</td>\n      <td>7.2</td>\n      <td>0</td>\n      <td>8.0</td>\n      <td>C26_L04_01_001</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>C26_L04_01_002_439009.jpg</td>\n      <td>2021-11-08</td>\n      <td>근대</td>\n      <td>청경근대</td>\n      <td>C26_L04_01_002_210907213908.jpg</td>\n      <td>생육기</td>\n      <td>2021-09-07 21:38:56</td>\n      <td>21.0</td>\n      <td>50.0</td>\n      <td>275.0</td>\n      <td>...</td>\n      <td>0.12</td>\n      <td>4.5</td>\n      <td>2021-09-07</td>\n      <td>6.2</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>3.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>C26_L04_01_002</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>C26_L04_01_002_439331.jpg</td>\n      <td>2021-11-08</td>\n      <td>근대</td>\n      <td>청경근대</td>\n      <td>C26_L04_01_002_210914133908.jpg</td>\n      <td>생육기</td>\n      <td>2021-09-14 13:38:59</td>\n      <td>19.0</td>\n      <td>51.0</td>\n      <td>265.0</td>\n      <td>...</td>\n      <td>0.14</td>\n      <td>4.8</td>\n      <td>2021-09-14</td>\n      <td>11.0</td>\n      <td>2</td>\n      <td>2.8</td>\n      <td>3.7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>C26_L04_01_002</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>242</th>\n      <td>C29_L04_02_009_551466.jpg</td>\n      <td>2021-11-25</td>\n      <td>근대</td>\n      <td>청경근대</td>\n      <td>C29_L04_01_009_211019171257.jpg</td>\n      <td>정식기</td>\n      <td>2021-10-19 17:12:24</td>\n      <td>19.0</td>\n      <td>48.0</td>\n      <td>394.0</td>\n      <td>...</td>\n      <td>0.18</td>\n      <td>4.2</td>\n      <td>2021-10-19</td>\n      <td>2.4</td>\n      <td>2</td>\n      <td>0.9</td>\n      <td>1.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>C29_L04_02_009</td>\n    </tr>\n    <tr>\n      <th>243</th>\n      <td>C29_L04_02_009_552167.jpg</td>\n      <td>2021-11-25</td>\n      <td>근대</td>\n      <td>청경근대</td>\n      <td>C29_L04_01_009_211026170959.jpg</td>\n      <td>생육기</td>\n      <td>2021-10-26 17:09:17</td>\n      <td>21.0</td>\n      <td>48.0</td>\n      <td>428.0</td>\n      <td>...</td>\n      <td>0.20</td>\n      <td>3.9</td>\n      <td>2021-10-26</td>\n      <td>4.7</td>\n      <td>4</td>\n      <td>1.1</td>\n      <td>1.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>C29_L04_02_009</td>\n    </tr>\n    <tr>\n      <th>244</th>\n      <td>C29_L04_02_009_553050.jpg</td>\n      <td>2021-11-25</td>\n      <td>근대</td>\n      <td>청경근대</td>\n      <td>C29_L04_01_009_211102160959.jpg</td>\n      <td>생육기</td>\n      <td>2021-11-02 16:09:47</td>\n      <td>21.0</td>\n      <td>47.0</td>\n      <td>385.0</td>\n      <td>...</td>\n      <td>0.22</td>\n      <td>4.0</td>\n      <td>2021-11-02</td>\n      <td>6.2</td>\n      <td>4</td>\n      <td>1.7</td>\n      <td>2.7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>C29_L04_02_009</td>\n    </tr>\n    <tr>\n      <th>245</th>\n      <td>C29_L04_02_009_553890.jpg</td>\n      <td>2021-11-25</td>\n      <td>근대</td>\n      <td>청경근대</td>\n      <td>C29_L04_01_009_211109160959.jpg</td>\n      <td>생육기</td>\n      <td>2021-11-09 16:09:38</td>\n      <td>21.0</td>\n      <td>48.0</td>\n      <td>336.0</td>\n      <td>...</td>\n      <td>0.25</td>\n      <td>3.9</td>\n      <td>2021-11-09</td>\n      <td>9</td>\n      <td>6</td>\n      <td>3</td>\n      <td>4.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>C29_L04_02_009</td>\n    </tr>\n    <tr>\n      <th>246</th>\n      <td>C29_L04_02_009_580489.jpg</td>\n      <td>2021-12-03</td>\n      <td>근대</td>\n      <td>청경근대</td>\n      <td>C29_L04_01_009_211116140959.jpg</td>\n      <td>수확기</td>\n      <td>2021-11-16 14:09:06</td>\n      <td>22.0</td>\n      <td>49.0</td>\n      <td>329.0</td>\n      <td>...</td>\n      <td>0.29</td>\n      <td>3.7</td>\n      <td>2021-11-16</td>\n      <td>10.8</td>\n      <td>8</td>\n      <td>4.5</td>\n      <td>4.7</td>\n      <td>0</td>\n      <td>4</td>\n      <td>C29_L04_02_009</td>\n    </tr>\n  </tbody>\n</table>\n<p>247 rows × 28 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = './1209.npy'\n",
    "data = np.load(path, allow_pickle=True)\n",
    "data = pd.DataFrame(data)\n",
    "data.columns=['filename_mod', 'create_date', 'crops', 'kind_type', 'fname', 'growth_stage', 'receive_date', \n",
    "              'temp_min', 'humi_min', 'co2_min', 'temp_max', 'humi_max', 'co2_max', 'temp_exp', 'humi_exp', 'co2_exp', \n",
    "              'ir_value', 'tl_value', 'ei_value', 'pl_value', 'measured_date', \n",
    " 'stem_length', 'leaf_cnt', 'leaf_width', 'leaf_length', 'stem_thick', 'fr_weight', 'cameranum']\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a819946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(opt): ## train_dataset, val_dataset, test_dataset, strain_dataset, sval_dataset, stest_dataset, wtrain_dataset, wval_dataset, wtest_dataset 구하기\n",
    "    ## opt에서 계속 가져옴\n",
    "    img_source = str(opt.source) + '/'\n",
    "      ## opt.source는 IMG_PATH\n",
    "    save_cashe = str(opt.save_cashe)\n",
    "      ## opt.save_cashe는 DATASET_PATH\n",
    "    if not opt.cashe :\n",
    "        columnz = [\"cameranum\",\"measured_date\",\"filename_mod\",\"fr_weight\",\"stem_length\",\"leaf_cnt\",\"leaf_length\",\"leaf_width\"]\n",
    "          ## 사용한 columns\n",
    "          ## crop_id 는 cameranum\n",
    "          ## 우리에 맞게 바꿔주기\n",
    "          ## day_capture에서 measured_date\n",
    "          ## 기존 json의 path는 image와 맞지 않았기 때문에 image와 맞게 새로 만든 filename_mod\n",
    "          ## weight에서 fr_weigth\n",
    "        dataFrame = pd.read_csv( opt.data, names=columnz).loc[1:,:]\n",
    "          ## 우리는 csv 말고 npy 사용할 예정\n",
    "        cnt = 0\n",
    "          ## 왜 개수를 셀까??\n",
    "\n",
    "        dataset, oneframex, imageset, idata =  None, None, None, None\n",
    "          ## dataset은 np.expand_dims(oneframex, axis=0)\n",
    "          ## dataset은 np.concatenate([dataset, np.expand_dims(oneframex, axis=0)])\n",
    "\n",
    "\n",
    "          ## oneframex는 imageset[index-opt.window:index,...]\n",
    "\n",
    "          ## imagesetdms np.concatenate([imageset, idata])\n",
    "\n",
    "          ## idata는 np.array([np.array(cv2.resize(mask,(opt.imgsz,opt.imgsz)))])\n",
    "\n",
    "        sdataset,oneframes, sensorset, sdata =  None, None, None, None\n",
    "          ## sdataset는 np.array([np.array([float(row['stem_length']),float(row['leaf_cnt']),float(row['leaf_length']),float(row['leaf_width'])])])\n",
    "          ## sdataset는 np.concatenate([sdataset, np.array([np.array([float(row['stem_length']),float(row['leaf_cnt']),float(row['leaf_length']),float(row['leaf_width'])])])])\n",
    "\n",
    "          ## oneframes, sensorset, sdata는 없음\n",
    "          ## 우리 데이터는 어떤 걸로 해야할지 고민\n",
    "\n",
    "        wdataset = np.array([])\n",
    "\n",
    "        nia_dataset, nia_oneframex, nia_imageset = None, None, np.full((20),None)  #제출용\n",
    "          ## nia_imageset은 np.full((20),None)\n",
    "          ## none값인 애들을 20행 만들기\n",
    "\n",
    "        for index, row in dataFrame.iterrows():\n",
    "          ## iterrows 메서드는 데이터의 행-열/데이터 정보를 튜플 형태의 generator 객체로 반환하는 메서드\n",
    "          ## index랑 row 가져옴\n",
    "            if not pd.isnull(row['leaf_length']):\n",
    "                cnt = cnt +1\n",
    "                print( f\"' index : {index-opt.window} -- cameranum : {dataFrame.loc[index-opt.window,'cameranum']} -- leaf_length : {dataFrame.loc[index-opt.window,'leaf_length']}\")\n",
    "                  ## loc로 crops_id랑 weight column 가져옴\n",
    "                print( f\"' index : {index} -- cameranum : {dataFrame.loc[index,'cameranum']} -- leaf_length : {dataFrame.loc[index,'leaf_length']}\")\n",
    "                  ## loc로 crops_id랑 weight column 가져옴\n",
    "\n",
    "                mask = img_mask (img_source+row['filename_mod'].split('/')[-1], True)\n",
    "                  ## img_source는 str(opt.source) + '/'\n",
    "                  ## opt.source는 image path\n",
    "                  ## [-1]은 이미지 파일 이름일듯\n",
    "\n",
    "                # cv2.imwrite('./wdataset/temp/'+row['paths'].split('/')[-1],cv2.resize(mask,(opt.imgsz,opt.imgsz)))\n",
    "\n",
    "                idata = np.array([np.array(cv2.resize(mask,(opt.imgsz,opt.imgsz)))])\n",
    "                  ## image resize 부분\n",
    "                  ##  resize는 위에서 64로 지정해줌\n",
    "                  ## image 가져온 걸 nparray로 변환해줌\n",
    "                  ## np.array(np.array[])로 차원 추가해줌 이미 3차원에 차원을 추가하면 (개수, 64, 64, 2) 이렇게 되는 건가?\n",
    "                  ## idata는 상위에서 만든 지역변수임\n",
    "\n",
    "\n",
    "                imageset = np.concatenate([imageset, idata])\n",
    "                  ## imageset은 아직 none인 상태였음\n",
    "                  ## nparray 상태인 이미지를 가져옴\n",
    "\n",
    "\n",
    "                nia_imageset = np.concatenate([nia_imageset, np.expand_dims(np.array(row['paths']), axis=0)])\n",
    "                  ## none값인 애들을 20행 만들기\n",
    "                  ## path는 이미지 이름인데 왜 가져오는지 모르겠음\n",
    "                  ## np.expend_dims는 차원을 추가함 axis=0임으로 행을 추가하기 때문에 1행 n열이 됨\n",
    "                  ## 우선 이미지를 가져왔다고 치기\n",
    "\n",
    "\n",
    "                oneframex = imageset[index-opt.window:index,...]\n",
    "                  ## window 는 time steps로 봄 default는 10으로 되어있음\n",
    "                  ## index-window : index는 10개를 계산해서 답을 도출한다는 뜻\n",
    "                  ## 어떻게 10개를 가져오는지 모르겠음 수정해볼 필요가 있음\n",
    "\n",
    "                nia_oneframex = nia_imageset[index-opt.window:index,...]\n",
    "                  ## nia_oneframex는 상위에서 None으로 선언함\n",
    "\n",
    "                if dataFrame.loc[index-opt.window,'cameranum'] == dataFrame.loc[index,'cameranum']:\n",
    "                    if row['leaf_length'] == '`' : \n",
    "                        row['leaf_length'] = np.nan\n",
    "                          ## none값 nan으로 대체\n",
    "                    if row['leaf_width'] == '`' : \n",
    "                        row['leaf_width'] = np.nan\n",
    "                          ## none값 nan으로 대체\n",
    "                    if dataset is None : \n",
    "                        sdataset = np.array([np.array([float(row['temp_min']),float(row['humi_min']),float(row['co2_min']),float(row['temp_max']),float(row['humi_max']),float(row['co2_max']),float(row['temp_exp']),float(row['humi_exp']),float(row['co2_exp']),float(row['ir_value']),float(row['tl_value']),float(row['ei_value']),float(row['pl_value'])])])\n",
    "                        # oneframez = np.expand_dims(oneframe, axis=0)\n",
    "                          ## dataset 상위에서 none으로 선언함\n",
    "                          ## sdataset 상위에서 none으로 선언함\n",
    "                          ## 생장정보들만 가져옴\n",
    "                        dataset = np.expand_dims(oneframex, axis=0)\n",
    "                          ## oneframex = imageset[index-opt.window:index,...]\n",
    "                          ## 한번에 학습시킬 이미지들 가져와서 행 추가\n",
    "                        nia_dataset = np.expand_dims(nia_oneframex, axis=0)\n",
    "                          ## nia_dataset 상위에서 none으로 선언함\n",
    "                          ## nia_dataset은 nia_imageset[index-opt.window:index,...]로 지정함\n",
    "                          ## dataset이랑 nia_dataset 차이를 모르겠음\n",
    "\n",
    "                    else :\n",
    "                        sdataset = np.array([np.array([float(row['temp_min']),float(row['humi_min']),float(row['co2_min']),float(row['temp_max']),float(row['humi_max']),float(row['co2_max']),float(row['temp_exp']),float(row['humi_exp']),float(row['co2_exp']),float(row['ir_value']),float(row['tl_value']),float(row['ei_value']),float(row['pl_value'])])])\n",
    "                            # oneframez = np.concatenate([oneframez, np.expand_dims(oneframe, axis=0)])\n",
    "                          ## 상위에서 sdata는 none값이었음, 여기서는 if 아닐 경우 else로해서 기존 sdataset에 concatenate 해줌\n",
    "\n",
    "                        dataset = np.concatenate([dataset, np.expand_dims(oneframex, axis=0)])\n",
    "                        nia_dataset = np.concatenate([nia_dataset, np.expand_dims(nia_oneframex, axis=0)])\n",
    "                    wdataset = np.concatenate([wdataset, np.array([float(dataFrame.loc[index,'leaf_length'])])])\n",
    "                      ## wdataset은 위에서 np.array([])로 선언\n",
    "                    print( f' index {index}  oneframex shape {oneframex.shape} wdataset shape {wdataset.shape}  dataset shape {dataset.shape} sdataset shape {sdataset.shape}')\n",
    "              ## 여기까지가 if not pd.isnull(row['weight']):일 경우\n",
    "            else :\n",
    "              ## weigt가 null일 경우들\n",
    "                print ( img_source + '/' + row['filename_mod'].split('/')[-1] )\n",
    "\n",
    "\n",
    "                mask = img_mask (img_source+row['filename_mod'].split('/')[-1], True)\n",
    "                  ## 위에서도 똑같이 mask = img_mask(img_source + row['paths'].split('/')[-1], True)\n",
    "\n",
    "                # cv2.imwrite('./wdataset/temp/'+row['paths'].split('/')[-1],cv2.resize(mask,(opt.imgsz,opt.imgsz)))\n",
    "\n",
    "                idata = np.array([np.array(cv2.resize(mask,(opt.imgsz,opt.imgsz)))])\n",
    "                  ## 위에서도 똑같이 idata = np.array([np.array(cv2.resize(mask,(opt.imgsz,opt.imgsz)))])\n",
    "\n",
    "                if imageset is None :\n",
    "                    imageset = idata\n",
    "                      ## image resize 부분\n",
    "                      ##  resize는 위에서 64로 지정해줌\n",
    "                      ## image 가져온 걸 nparray로 변환해줌\n",
    "                      ## np.array(np.array[])로 차원 추가해줌 이미 3차원에 차원을 추가하면 (개수, 64, 64, 2) 이렇게 되는 건가?\n",
    "                      ## idata는 상위에서 만든 지역변수임\n",
    "                    nia_imageset = np.expand_dims(np.array(row['filename_mod']), axis=0)\n",
    "                      ## none값인 애들을 20행 만들기\n",
    "                      ## path는 이미지 이름인데 왜 가져오는지 모르겠음\n",
    "                      ## np.expend_dims는 차원을 추가함 axis=0임으로 행을 추가하기 때문에 1행 n열이 됨\n",
    "                      ## 우선 이미지를 가져왔다고 치기\n",
    "\n",
    "                else :\n",
    "                    imageset = np.concatenate([imageset, idata])\n",
    "                      ## image resize 부분\n",
    "                      ##  resize는 위에서 64로 지정해줌\n",
    "                      ## image 가져온 걸 nparray로 변환해줌\n",
    "                      ## np.array(np.array[])로 차원 추가해줌 이미 3차원에 차원을 추가하면 (개수, 64, 64, 2) 이렇게 되는 건가?\n",
    "                      ## idata는 상위에서 만든 지역변수임\n",
    "                    nia_imageset = np.concatenate([nia_imageset, np.expand_dims(np.array(row['filename_mod']), axis=0)])\n",
    "                      ## none값인 애들을 20행 만들기\n",
    "                      ## path는 이미지 이름인데 왜 가져오는지 모르겠음\n",
    "                      ## np.expend_dims는 차원을 추가함 axis=0임으로 행을 추가하기 때문에 1행 n열이 됨\n",
    "                      ## 우선 이미지를 가져왔다고 치기\n",
    "\n",
    "\n",
    "        print( f'count = {cnt}')\n",
    "          ## cnt로 계산함\n",
    "\n",
    "        indexes = np.arange(dataset.shape[0])\n",
    "          ## dataset 개수만큼\n",
    "          ## idata = np.array([np.array(cv2.resize(mask, (opt.imgsz, opt.imgsz)))])\n",
    "          ## imageset = np.concatenate([imageset, idata])\n",
    "          ## oneframex = imageset[index-opt.window:index,...]\n",
    "          ## dataset = np.expand_dims(oneframex, axis=0)\n",
    "\n",
    "        np.random.shuffle(indexes)\n",
    "          ## sdataset(길이), wdataset(무게)도 같은 index 사용\n",
    "          ## 여기서는 lstm과 별개로 cnn만 돌리기 때문에 섞어도 됨\n",
    "\n",
    "        train_index = indexes[: int(0.8 * dataset.shape[0])]\n",
    "        val_index = indexes[int(0.8 * dataset.shape[0]) : int(0.9 * dataset.shape[0])]\n",
    "        test_index = indexes[int(0.9 * dataset.shape[0]) :]\n",
    "          ## index 를 train, val, test로 나눔\n",
    "\n",
    "        train_dataset = dataset[train_index]\n",
    "        val_dataset = dataset[val_index]\n",
    "        test_dataset = dataset[test_index]\n",
    "\n",
    "        strain_dataset = sdataset[train_index]\n",
    "        sval_dataset = sdataset[val_index]\n",
    "        stest_dataset = sdataset[test_index]\n",
    "\n",
    "        # weight train set\n",
    "        wtrain_dataset = wdataset[train_index]\n",
    "        wval_dataset = wdataset[val_index]\n",
    "        wtest_dataset = wdataset[test_index]\n",
    "\n",
    "        write_dataset(save_cashe + '/train_data.txt',wtrain_dataset.tolist() , nia_dataset[train_index].tolist() ,strain_dataset.tolist())\n",
    "        write_dataset(save_cashe + '/val_data.txt',wval_dataset.tolist() , nia_dataset[val_index].tolist() ,sval_dataset.tolist())\n",
    "        write_dataset(save_cashe + '/test_data.txt',wtest_dataset.tolist() , nia_dataset[test_index].tolist() ,stest_dataset.tolist())\n",
    "          ## 저장하기\n",
    "          ## w, s, nia 한번에 저장\n",
    "        np.save( save_cashe + '/train_dataset',train_dataset )\n",
    "        np.save( save_cashe + '/val_dataset',val_dataset )\n",
    "        np.save( save_cashe + '/test_dataset',test_dataset )\n",
    "        np.save( save_cashe + '/strain_dataset',strain_dataset )\n",
    "        np.save( save_cashe + '/sval_dataset',sval_dataset )\n",
    "        np.save( save_cashe + '/stest_dataset',stest_dataset )\n",
    "\n",
    "        np.save( save_cashe + '/wtrain_dataset',wtrain_dataset )\n",
    "        np.save( save_cashe + '/wval_dataset',wval_dataset )\n",
    "        np.save( save_cashe + '/wtest_dataset',wtest_dataset )\n",
    "          ## 각각 .npy로 저장\n",
    "        \n",
    "    else:\n",
    "          ## opt.cashe 있으면 불러오기\n",
    "        train_dataset = np.load( save_cashe + '/train_dataset.npy' )\n",
    "        val_dataset = np.load( save_cashe + '/val_dataset.npy' )\n",
    "        test_dataset = np.load( save_cashe + '/test_dataset.npy' )\n",
    "        strain_dataset = np.load( save_cashe + '/strain_dataset.npy' )\n",
    "        sval_dataset = np.load( save_cashe + '/sval_dataset.npy' )\n",
    "        stest_dataset = np.load( save_cashe + '/stest_dataset.npy' )\n",
    "\n",
    "        wtrain_dataset = np.load( save_cashe + '/wtrain_dataset.npy' )\n",
    "        wval_dataset = np.load( save_cashe + '/wval_dataset.npy' )\n",
    "        wtest_dataset = np.load( save_cashe + '/wtest_dataset.npy' )\n",
    "\n",
    "\n",
    "        print( f' train_dataset shape {train_dataset.shape} strain_dataset shape {strain_dataset.shape}  wtrain_dataset shape {wtrain_dataset.shape}')\n",
    "\n",
    "    # Normalize the data to the 0-1 range.\n",
    "      ## Normalization (정규화) 특성들을 특정 범위(주로 [0,1]) 로 스케일링 하는 것, 가작 작은 값은 0, 가장 큰 값은 1 \n",
    "    train_dataset = train_dataset / 255\n",
    "    val_dataset = val_dataset / 255\n",
    "    test_dataset = test_dataset / 255\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "      ## (표준화) 특성들의 평균을 0, 분산을 1 로 스케일링, 특성들을 정규분포로 만듬\n",
    "\n",
    "    strain_dataset = scaler.fit_transform(strain_dataset)\n",
    "      ## train은 .fit_transform 나머지는 .tranform\n",
    "    sval_dataset = scaler.transform(sval_dataset)\n",
    "    stest_dataset = scaler.transform(stest_dataset)\n",
    "\n",
    "    strain_dataset = np.where(np.isnan(strain_dataset), 0, strain_dataset)\n",
    "    sval_dataset = np.where(np.isnan(sval_dataset), 0, sval_dataset)\n",
    "    stest_dataset = np.where(np.isnan(stest_dataset), 0, stest_dataset)\n",
    "      ## 조건 맞는 곳의 특정 값 변경\n",
    "      ## data에서 nan인 값들을 0으로 바꾸겠다\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset, strain_dataset, sval_dataset, stest_dataset, wtrain_dataset, wval_dataset, wtest_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f45a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input할 데이터들 shape 바꿔주기\n",
    "\n",
    "def create_shifted_frames(data):\n",
    "    x = data[:, 0 : data.shape[1] - 1, :, :]\n",
    "    #x = data[:, 9 : data.shape[1] - 1, :, :]\n",
    "    y = data[:, -1 , :, :]\n",
    "    return x, y\n",
    "\n",
    "  ## image shifted로 shape 통일\n",
    "  ## 값이 x, y 2개 나옴\n",
    "\n",
    "def create_shifted_env(data):\n",
    "    x = data[:, 0 : data.shape[1] - 1,:]\n",
    "    #x = data[:, 9 : data.shape[1] - 1]\n",
    "    y = data[:, -1,:]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d173837b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# opt 지정\n",
    "def parse_opt():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data', default = DATACSV_PATH, help='dataset.yaml path')\n",
    "    parser.add_argument('--weights', nargs='+', type=str, default= DATASET_PATH, help='model.h5 path(s)')\n",
    "    parser.add_argument('--batch', type=int, default=15, help='batch size')\n",
    "    parser.add_argument('--epochs', type=int, default=100, help='epochs size')\n",
    "    parser.add_argument('--imgsz', '--img', '--img-size', type=int, default=RESIZE, help='inference size (pixels)')\n",
    "    parser.add_argument('--task', default='train', help='train, test, predict')\n",
    "    parser.add_argument('--source', default= IMG_PATH, help='orignal crop information list or image for predict')\n",
    "    parser.add_argument('--save_cashe', default= DATASET_PATH / 'vegetable_size', help=' train dataset location ')\n",
    "    parser.add_argument('--window', default=10, help='lstm window')\n",
    "    parser.add_argument('--type', default='vegetable', help='strawberry or vegetable')\n",
    "    parser.add_argument('--cashe', action='store_true', help='read cashe dataset to train')\n",
    "    parser.add_argument('--detect', action='store_true', help='detect dataset ')\n",
    "    opt = parser.parse_args()\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73277507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting easydict\n",
      "  Downloading easydict-1.10.tar.gz (6.4 kB)\n",
      "Building wheels for collected packages: easydict\n",
      "  Building wheel for easydict (setup.py): started\n",
      "  Building wheel for easydict (setup.py): finished with status 'done'\n",
      "  Created wheel for easydict: filename=easydict-1.10-py3-none-any.whl size=6506 sha256=74a3cfe3019db945eacbb0ffd676caf1caa1191e7c8087b29bb7f7fc79b7e0f3\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\0d\\9a\\a9\\02f3a5f0c6b2c57184661770360c58db8166f5c877780e98f2\n",
      "Successfully built easydict\n",
      "Installing collected packages: easydict\n",
      "Successfully installed easydict-1.10\n"
     ]
    }
   ],
   "source": [
    "!pip install easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44ca62a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import easydict\n",
    "# def parse_opt():\n",
    "#     args = easydict.EasyDict({\n",
    "# # \n",
    "#             \"data\": DATACSV_PATH,\n",
    "\n",
    "#             \"weights\": DATASET_PATH,\n",
    "\n",
    "#             \"batch\": 15,\n",
    "\n",
    "#             \"epochs\": \"100\",\n",
    "\n",
    "#             'imgsz' : RESIZE,\n",
    "        \n",
    "#             'img' : RESIZE,\n",
    "        \n",
    "#             'img-size': RESIZE,\n",
    "\n",
    "#             \"task\": 'train',\n",
    "            \n",
    "#             \"source\": IMG_PATH,\n",
    "           \n",
    "#             \"save_cashe\" : DATASET_PATH,\n",
    "        \n",
    "#             \"window\" : 10,\n",
    "            \n",
    "#             \"type\" : 'vegetable',\n",
    "        \n",
    "#             \"cashe\" : 'store_true',\n",
    "        \n",
    "#             \"detect\" : 'store_true'\n",
    "\n",
    "#     })\n",
    "    \n",
    "# #     return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "615371e1",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9566ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(opt):\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset, strain_dataset, sval_dataset, stest_dataset, wtrain_dataset, wval_dataset, wtest_dataset = read_dataset(opt)\n",
    "    \n",
    "    # Apply the processing function to the image datasets.\n",
    "    x_train, y_train = create_shifted_frames(train_dataset)\n",
    "    x_val, y_val = create_shifted_frames(val_dataset)\n",
    "    x_test, y_test = create_shifted_frames(test_dataset)\n",
    "\n",
    "    # Apply the processing function to the env datasets.\n",
    "    x_strain = strain_dataset\n",
    "    x_sval = sval_dataset\n",
    "    x_stest = stest_dataset\n",
    "\n",
    "    # Apply the processing function to the weight datasets.\n",
    "    y_trainY = wtrain_dataset.reshape(1,-1)\n",
    "    y_valY = wval_dataset.reshape(1,-1)\n",
    "    y_testY = wtest_dataset.reshape(1,-1)\n",
    "\n",
    "    y_trainY= np.reshape(y_trainY, (y_trainY.shape[1],1))\n",
    "    y_valY= np.reshape(y_valY, (y_valY.shape[1],1))\n",
    "    y_testY= np.reshape(y_testY, (y_testY.shape[1],1))\n",
    "\n",
    "    sc = MinMaxScaler()\n",
    "    # sc = StandardScaler()\n",
    "\n",
    "    y_trainY[:] = sc.fit_transform(y_trainY[:])\n",
    "    y_valY[:] = sc.transform(y_valY[:])\n",
    "    y_testY[:] = sc.transform(y_testY[:])\n",
    "\n",
    "\n",
    "    # output layer\n",
    "\n",
    "    # Inspect the dataset.\n",
    "    print(\"Training Dataset Shapes: \" + str(x_train.shape) + \", \" + str(y_train.shape))\n",
    "    print(\"Validation Dataset Shapes: \" + str(x_val.shape) + \", \" + str(y_val.shape)) \n",
    "\n",
    "\n",
    "    # Construct a figure on which we will visualize the images.\n",
    "    fig, axes = plt.subplots(4, 5, figsize=(10, 8))\n",
    "\n",
    "    # Plot each of the sequential images for one random data example.\n",
    "    data_choice = np.random.choice(range(len(train_dataset)), size=1)[0]\n",
    "    for idx, ax in enumerate(axes.flat):\n",
    "        if  train_dataset.shape[1] > idx :\n",
    "            ax.imshow(np.squeeze(train_dataset[data_choice][idx]), cmap=\"gray\")\n",
    "            ax.set_title(f\"Frame {idx + 1}\")\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    # Print information and display the figure.\n",
    "    print(f\"Displaying frames for example {data_choice}.\")\n",
    "    plt.show()\n",
    "\n",
    "    \"\"\"\n",
    "    ## Model Construction\n",
    "\n",
    "    \"\"\"\n",
    "        ## opt.type으로 할 일 정해줌\n",
    "\n",
    "    if opt.task == 'train':\n",
    "\n",
    "        # Construct the input layer with no definite frame size.\n",
    "        inp = layers.Input(shape=(None, *x_train.shape[2:]), name='imgInput')\n",
    "          ## image input으로 넣음\n",
    "\n",
    "        # We will construct 3 `ConvLSTM2D` layers with batch normalization,\n",
    "        # followed by a `Conv3D` layer for the spatiotemporal outputs.\n",
    "        x = layers.ConvLSTM2D(\n",
    "            filters=64,\n",
    "            kernel_size=(5, 5),\n",
    "            padding=\"same\",\n",
    "            return_sequences=True,\n",
    "            activation=\"relu\",\n",
    "        )(inp)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.ConvLSTM2D(\n",
    "            filters=64,\n",
    "            kernel_size=(3, 3),\n",
    "            padding=\"same\",\n",
    "            return_sequences=True,\n",
    "            activation=\"relu\",\n",
    "        )(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.ConvLSTM2D(\n",
    "            filters=64,\n",
    "            kernel_size=(1, 1),\n",
    "            padding=\"same\",\n",
    "            return_sequences=True,\n",
    "            activation=\"relu\",\n",
    "        )(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.ConvLSTM2D(\n",
    "            filters=64,\n",
    "            kernel_size=(2, 2),\n",
    "            padding=\"same\",\n",
    "            return_sequences=False,\n",
    "            activation=\"relu\",\n",
    "        )(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        xImg = layers.Conv2D(\n",
    "            filters=3, kernel_size=(3, 3), activation=\"sigmoid\", padding=\"same\", name='next'\n",
    "        )(x)\n",
    "\n",
    "        # env model\n",
    "        inp_env = layers.Input(shape=(x_strain.shape[1]), name='envInput')\n",
    "          ## 환경 정보 input으로\n",
    "        size = layers.Dense(500, activation='relu')(inp_env)\n",
    "        size = layers.Dense(384, activation='relu')(size)\n",
    "\n",
    "        xEnv_flattern = layers.Flatten()(size)\n",
    "         ## image 정보 flatten 레이어\n",
    "\n",
    "        # weight model\n",
    "        y = layers.MaxPool2D(pool_size=32)(x)\n",
    "        y = layers.Dense(84, activation='relu')(y)\n",
    "        y = layers.Dense(30, activation='relu')(y)\n",
    "        y = layers.Flatten()(y)\n",
    "\n",
    "        # merge image + env\n",
    "        y = layers.concatenate([y, xEnv_flattern])\n",
    "          ## 여기서 image랑 환경 정보 합침\n",
    "\n",
    "\n",
    "        if opt.type == 'strawberry':        #=====> 딸기\n",
    "            print(\"=================> 딸기 \")\n",
    "            y = layers.Dense(512, activation='relu')(y)\n",
    "            y = layers.Dropout(0.5)(y)\n",
    "            y = layers.Dense(100, activation='relu')(y)\n",
    "            y = layers.Dropout(0.5)(y)\n",
    "            y = layers.Dense(25, activation='relu')(y)\n",
    "            y = layers.Dense(1, name='leaf_length')(y)\n",
    "        else:                               #=====> 엽채\n",
    "            print(\"=================> 엽채 모델\")\n",
    "            y = layers.Dense(500, activation='relu')(y)\n",
    "            y = layers.Dense(320, activation='relu')(y)\n",
    "            y = layers.Dense(384, activation='relu')(y)\n",
    "            y = layers.Dense(448, activation='relu')(y)\n",
    "            y = layers.Dense(160, activation='relu')(y)\n",
    "            y = layers.Dense(160, activation='relu')(y)\n",
    "            y = layers.Dense(32, activation='relu')(y)\n",
    "            y = layers.Dense(1, name='leaf_length')(y)\n",
    "\n",
    "        # Next, we will build the complete model and compile it.\n",
    "        model = keras.models.Model(inputs=[inp,inp_env], outputs=[y])\n",
    "          ## 모델 input 정해주기\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        model.compile(\n",
    "            loss={'leaf_length': root_mean_squared_error}, \n",
    "            # loss={'next':keras.losses.binary_crossentropy, 'env': keras.losses.mean_squared_error, 'weigth': keras.losses.mean_absolute_percentage_error}, \n",
    " \n",
    "            # [ keras.losses.binary_crossentropy, keras.losses.mean_squared_error, keras.losses.mean_squared_error], \n",
    "            optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        ## Model Training\n",
    "\n",
    "        With our model and data constructed, we can now train the model.\n",
    "        \"\"\"\n",
    "\n",
    "        # Define some callbacks to improve training.\n",
    "        early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "        reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "        # Define modifiable training hyperparameters.\n",
    "        epochs = opt.epochs\n",
    "        batch_size =opt.batch\n",
    "\n",
    "        # Fit the model to the training data.\n",
    "        model.fit( \n",
    "            { 'imgInput': x_train, 'envInput' : x_strain },\n",
    "            { 'leaf_length': y_trainY },\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data= ([x_val,x_sval], [y_valY]),\n",
    "            # callbacks=[early_stopping, reduce_lr],\n",
    "        )\n",
    "          ## 모델 학습\n",
    "        model.save( opt.weights )\n",
    "\n",
    "    elif opt.task == 'test':\n",
    " \n",
    "        model = load_model (opt.weights, custom_objects={'root_mean_squared_error': root_mean_squared_error})\n",
    "        model.evaluate([x_test,x_stest],[y_testY], batch_size=opt.batch)\n",
    "\n",
    "        print('test')\n",
    "\n",
    "    elif opt.task == 'predict':\n",
    "\n",
    "        # Select a random example from the validation dataset.\n",
    "        # example = test_dataset[np.random.choice(range(len(val_dataset)), size=1)[0]]\n",
    "\n",
    "        # Pick the first/last ten frames from the example.\n",
    "        # frames = example[0:18, ...]\n",
    "\n",
    "        # Predict a new set of 10 frames.\n",
    "            # Extract the model's prediction and post-process it.\n",
    "        model = load_model (opt.weights)\n",
    "          ## keras에 있는 load모델 가져옴\n",
    "        new_prediction = model.predict([x_test[0:10],x_stest[0:10]])\n",
    "\n",
    "        print(mean_squared_error(y_testY[0:10]*100, new_prediction[2]*100))\n",
    "\n",
    "        print((new_prediction[2]-y_testY[0:10])*100)\n",
    "        print(new_prediction[2]*100)\n",
    "        print(y_testY[0:10]*100)\n",
    "        # print(y_testY[0:10])\n",
    "            # Extend the set of prediction frames.\n",
    "\n",
    "        # # Construct a figure for the original and new frames.\n",
    "        # fig, axes = plt.subplots(2, 10, figsize=(20, 4))\n",
    "\n",
    "        # # Plot the original frames.\n",
    "        # for idx, ax in enumerate(axes[0]):\n",
    "        #     ax.imshow(np.squeeze(test_dataset[0][idx]), cmap=\"gray\")\n",
    "        #     ax.set_title(f\"Frame {idx }\")\n",
    "        #     ax.axis(\"off\")\n",
    "\n",
    "        # ax.imshow(np.squeeze(new_prediction), cmap=\"gray\")\n",
    "        # ax.set_title(f\"Frame new\")\n",
    "        # ax.axis(\"off\")\n",
    "\n",
    "        # # Display the figure.\n",
    "        # plt.show()\n",
    "\n",
    "        # print('predict')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a8f3e99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [16]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m----> 2\u001B[0m     opt \u001B[38;5;241m=\u001B[39m \u001B[43mparse_opt\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m     main(opt)\n",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36mparse_opt\u001B[1;34m()\u001B[0m\n\u001B[0;32m      9\u001B[0m parser\u001B[38;5;241m.\u001B[39madd_argument(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m--task\u001B[39m\u001B[38;5;124m'\u001B[39m, default\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m, help\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain, test, predict\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     10\u001B[0m parser\u001B[38;5;241m.\u001B[39madd_argument(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m--source\u001B[39m\u001B[38;5;124m'\u001B[39m, default\u001B[38;5;241m=\u001B[39m IMG_PATH, help\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124morignal crop information list or image for predict\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 11\u001B[0m parser\u001B[38;5;241m.\u001B[39madd_argument(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m--save_cashe\u001B[39m\u001B[38;5;124m'\u001B[39m, default\u001B[38;5;241m=\u001B[39m \u001B[43mDATASET_PATH\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mvegetable_size\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m, help\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m train dataset location \u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     12\u001B[0m parser\u001B[38;5;241m.\u001B[39madd_argument(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m--window\u001B[39m\u001B[38;5;124m'\u001B[39m, default\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, help\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlstm window\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     13\u001B[0m parser\u001B[38;5;241m.\u001B[39madd_argument(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m--type\u001B[39m\u001B[38;5;124m'\u001B[39m, default\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvegetable\u001B[39m\u001B[38;5;124m'\u001B[39m, help\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstrawberry or vegetable\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mTypeError\u001B[0m: unsupported operand type(s) for /: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    opt = parse_opt()\n",
    "    main(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d33862b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [ 44,  39,  41],\n",
       "        [ 44,  39,  41],\n",
       "        [ 44,  39,  41]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [ 44,  39,  41],\n",
       "        [ 44,  39,  41],\n",
       "        [ 44,  39,  41]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [ 44,  39,  41],\n",
       "        [ 44,  39,  41],\n",
       "        [ 44,  39,  41]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [200, 190, 190],\n",
       "        [201, 191, 191],\n",
       "        [201, 191, 191]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [200, 190, 190],\n",
       "        [201, 191, 191],\n",
       "        [201, 191, 191]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [200, 190, 190],\n",
       "        [201, 191, 191],\n",
       "        [201, 191, 191]]], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_mask(\"C:\\\\Users\\\\pc\\\\test1.jpg\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ff0c24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
